{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/v/miniconda3/envs/aim2/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/v/miniconda3/envs/aim2/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/v/miniconda3/envs/aim2/lib/python3.9/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/v/miniconda3/envs/aim2/lib/python3.9/site-packages (from requests) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/v/miniconda3/envs/aim2/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API key authentication\n",
    "\n",
    "The TMDb API (The Movie Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\":true,\"status_code\":1,\"status_message\":\"Success.\"}\n"
     ]
    }
   ],
   "source": [
    "#code from the api reference site\n",
    "# https://developer.themoviedb.org/reference/intro/getting-started\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/authentication\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI0NDUzZjczY2Q0MDY5Yjg1M2MyY2QwZTM4NTFhYTNjYiIsInN1YiI6IjY1ZDI4MmE0MjhkN2ZlMDE3YzM0NDYxMyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.RjO6h2nQWhYcuuWdoRaKZpyR740EPxdH9D29Tfcodk8\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of this code has been created by prompting ChatGPT and then editing and restructuring it for the needs of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a film dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dataset of the current top 20 trending films.\n",
    "\n",
    "*This dataset was created as a tester for the rest of the code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of films added to the CSV: 20\n",
      "Data saved to movie_data.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# got the code and logic from ChatGPT\n",
    "# used ChatGPT to provide code to create a csv file with film details from the TMDb API\n",
    "# provided the above code as reference\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/trending/movie/day?language=en-US\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI0NDUzZjczY2Q0MDY5Yjg1M2MyY2QwZTM4NTFhYTNjYiIsInN1YiI6IjY1ZDI4MmE0MjhkN2ZlMDE3YzM0NDYxMyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.RjO6h2nQWhYcuuWdoRaKZpyR740EPxdH9D29Tfcodk8\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()['results']  \n",
    "    \n",
    "    # saving the film data\n",
    "    # naming the CSV file \n",
    "    file_name = 'movie_data.csv'\n",
    "    # extracting the headers from the first movie for the CSV\n",
    "    headers = data[0].keys()\n",
    "    # writing data onto the CSV file\n",
    "    with open(file_name, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    # printing the number of films added to the CSV\n",
    "    no_films_added = len(data)\n",
    "    print(f\"Number of films added to the CSV: {no_films_added}\")    \n",
    "    print(f\"Data saved to {file_name}\")\n",
    "else:\n",
    "    print(\"Failed to fetch movie data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading film posters using the tester film dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used ChatGPT for the code & logic\n",
    "# made minor edits such as adding a variable to count the number of posters downloaded\n",
    "\n",
    "# selecting the CSV file to read\n",
    "csv_file_name = 'movie_data.csv'\n",
    "\n",
    "# naming/selecting the poster folder\n",
    "poster_folder = 'posters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posters downloaded: 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# creating the folder if it doesn't exist\n",
    "os.makedirs(poster_folder, exist_ok=True)\n",
    "\n",
    "# variable to count the number of posters downloaded\n",
    "num_posters_downloaded = 0\n",
    "\n",
    "# function to download the posters of the films\n",
    "def download_poster(poster_url, save_path):\n",
    "    response = requests.get(poster_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# code to read the CSV and pull the URLs to download images\n",
    "with open(csv_file_name, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        # extracting poster path and movie ID from the row\n",
    "        poster_path = row['poster_path']\n",
    "        movie_id = row['id']\n",
    "        if poster_path:\n",
    "            # constructing the full URL for the poster image\n",
    "            poster_url = f\"https://image.tmdb.org/t/p/original{poster_path}\"\n",
    "            # defining the file path to save the poster image\n",
    "            poster_save_path = os.path.join(poster_folder, f\"{movie_id}.jpg\")\n",
    "            # downloading the poster image\n",
    "            if download_poster(poster_url, poster_save_path):\n",
    "                num_posters_downloaded += 1\n",
    "\n",
    "# printing the total number of posters downloaded\n",
    "print(f\"Number of posters downloaded: {num_posters_downloaded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dataset of the **current most popular** films on The Movie Database\n",
    "\n",
    "- The TMDb API allows thhe user to download the details of 20 films at a time\n",
    "- Used ChatGPT to modify the previous download code to support a larger pull\n",
    "- Results from the TMDb API display 20 films per page\n",
    "- Selecting the number of pages is how the user can select the number of movies & their details to pull\n",
    "- For example, 5 pages pulls a 100 films, 10 pages pulls 200 films, etc.\n",
    "- Through trail and error, I figured out that the API allows for the extraction of 500 result pages in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming/slecting the csv file\n",
    "file_path = 'movie_data_hindi_10k.csv'\n",
    "\n",
    "# select number of pages - each results page contains a list of 20 films\n",
    "num_pages = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of films added to the CSV: 7621\n",
      "Data saved to movie_data_hindi_10k.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/discover/movie\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI0NDUzZjczY2Q0MDY5Yjg1M2MyY2QwZTM4NTFhYTNjYiIsInN1YiI6IjY1ZDI4MmE0MjhkN2ZlMDE3YzM0NDYxMyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.RjO6h2nQWhYcuuWdoRaKZpyR740EPxdH9D29Tfcodk8\"\n",
    "}\n",
    "\n",
    "# creating an empty list to store data from all pages\n",
    "all_data = []\n",
    "\n",
    "for page in range(1, num_pages + 1):\n",
    "    # these are filters for the API\n",
    "    # I have also chosen to pull films based on popularity - the current most popular films\n",
    "    params = {\n",
    "        \"include_adult\": \"false\",\n",
    "        \"include_video\": \"false\",\n",
    "        \"language\": \"en\",\n",
    "        \"sort_by\": \"popularity.desc\",\n",
    "        \"with_original_language\": \"hi\", #choosing the original language - i chose english, hindi and french and made 3 databases\n",
    "        \"page\": page\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()['results']  # extracting the results\n",
    "        all_data.extend(data)\n",
    "    else:\n",
    "        print(f\"Failed to fetch movie data for page {page}\")\n",
    "\n",
    "# extracting the headers from the first movie for the CSV\n",
    "if all_data:\n",
    "    headers = all_data[0].keys()\n",
    "    \n",
    "    # writing the data onto CSV file\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_data)\n",
    "    \n",
    "    # printing the number of films added to the CSV\n",
    "    num_films_added = len(all_data)\n",
    "    print(f\"Number of films added to the CSV: {num_films_added}\")\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "else:\n",
    "    print(\"No movie data fetched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading film posters using the above film dataset (same as the above code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the CSV file to read\n",
    "csv_file = 'movie_data_hindi_7k.csv'\n",
    "\n",
    "# naming/selecting the poster folder\n",
    "poster_folder_name = 'movie_posters_hindi_7k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posters downloaded: 6626\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# creating the folder if it doesn't exist\n",
    "os.makedirs(poster_folder_name, exist_ok=True)\n",
    "\n",
    "# variable to count the number of posters downloaded\n",
    "num_posters_downloaded = 0\n",
    "\n",
    "# function to download the posters of the films\n",
    "def download_poster(poster_url, save_path):\n",
    "    response = requests.get(poster_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# code to read the CSV and pull the URLs to download images\n",
    "with open(csv_file, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        # extracting poster path and movie ID from the row\n",
    "        poster_path = row['poster_path']\n",
    "        movie_id = row['id']\n",
    "        if poster_path:\n",
    "            # constructing the full URL for the poster image\n",
    "            poster_url = f\"https://image.tmdb.org/t/p/original{poster_path}\"\n",
    "            # defining the file path to save the poster image\n",
    "            poster_save_path = os.path.join(poster_folder_name, f\"{movie_id}.jpg\")\n",
    "            # downloading the poster image\n",
    "            if download_poster(poster_url, poster_save_path):\n",
    "                num_posters_downloaded += 1\n",
    "\n",
    "# printing the total number of posters downloaded\n",
    "print(f\"Number of posters downloaded: {num_posters_downloaded}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
